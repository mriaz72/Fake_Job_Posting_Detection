{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1bY6hxfktjLaCxMdnuWuEqOpQ8q2O6GRi","authorship_tag":"ABX9TyN/SAPvHxXi6wqEoNdRfFi2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Setup, Library Installation, and Data Preparation\n","We have load the necessary libraries and segment the dataset to create our knowledge base of real jobs."],"metadata":{"id":"2V6Ev-tJKwej"}},{"cell_type":"code","source":["!pip install -U langchain langchain-community sentence-transformers faiss-cpu -qq\n"],"metadata":{"id":"LttMmg45MID4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import pandas as pd\n","import numpy as np\n","import faiss\n","from sentence_transformers import SentenceTransformer\n","from langchain_community.embeddings import SentenceTransformerEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.documents import Document\n"],"metadata":{"id":"_HcX3ehvLA9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Load the raw dataset\n","df = pd.read_csv('/content/drive/MyDrive/Fake_Job_Posting_Detection/data/raw/fake_job_postings.csv')\n","df.fillna('', inplace=True)\n","df.head(3)"],"metadata":{"id":"wdJz8oIWLcnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Setup Embedding Model\n","model_name = 'all-MiniLM-L6-v2'\n","model = SentenceTransformer(model_name)\n","embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n","\n","print(f\"Sentence Transformer Model ({model_name}) loaded.\")"],"metadata":{"id":"lIObRGiBNpU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Create the Knowledge Base Source (Real Job Postings)\n","# Filter for verified Real Job Postings (fraudulent == 0)\n","real_jobs_df = df[df['fraudulent'] == 0].sample(n=300, random_state=42)\n","# Sampling 300 posts as requested for a focused knowledge base.\n","\n","print(f\"Knowledge Base Source created with {len(real_jobs_df)} verified real job postings.\")"],"metadata":{"id":"bftrPHE6N3JZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Build the Vector Store (FAISS)\n","We have embed the text of the real job postings and store them in FAISS for fast retrieval."],"metadata":{"id":"IhBBLIs9OQV6"}},{"cell_type":"code","source":["# Embed Real Postings and Build FAISS Vector Store\n","\n","# Function to combine relevant text fields for the knowledge base\n","def combine_job_text(row):\n","    return (f\"Title: {row['title']}. Company: {row['company_profile']}. \"\n","            f\"Description: {row['description']}. Requirements: {row['requirements']}\")\n","\n","# 1. Prepare Documents\n","real_job_documents = []\n","for index, row in real_jobs_df.iterrows():\n","    real_job_documents.append(\n","        Document(\n","            page_content=combine_job_text(row),\n","            metadata={\"job_id\": row['job_id'], \"title\": row['title']}\n","        )\n","    )\n","\n"],"metadata":{"id":"Nw61AK5xOI0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Create FAISS Vector Store\n","# This process embeds the text content of all 300 real jobs.\n","real_job_kb = FAISS.from_documents(real_job_documents, embedding_function)\n","print(f\"FAISS Vector Store built with embeddings from {len(real_job_documents)} real job postings.\")"],"metadata":{"id":"w3O4hP60Of6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Implement the Advanced Retrieval Function\n","This function retrieves the most similar real job postings and uses them to explain why a suspicious post differs from the norm."],"metadata":{"id":"poRi0TUkOv7_"}},{"cell_type":"code","source":["#  Retrieval and Generation Function (Similarity-Based Explanation)\n","\n","def retrieve_and_explain_similarity(suspicious_job_text, real_job_kb, top_k=3):\n","    \"\"\"Retrieves similar real jobs to contrast with the suspicious job.\"\"\"\n","\n","    # 1. Retrieval: Find top_k most similar (legitimate) job postings\n","    retrieved_docs = real_job_kb.similarity_search(suspicious_job_text, k=top_k)\n","\n","    # 2. Construct the Prompt (Simulated LLM)\n","    context_list = []\n","    for i, doc in enumerate(retrieved_docs):\n","        # Limit content length for cleaner output\n","        content_snippet = doc.page_content[:150].replace('\\n', ' ') + '...'\n","        context_list.append(f\"Example {i+1} (Title: {doc.metadata['title']}): {content_snippet}\")\n","\n","    context_str = \"\\n\".join(context_list)\n","\n","    # 3. Generation (Simulated for this project)\n","    # The actual LLM prompt would ask for a contrastive explanation:\n","\n","    simulated_explanation = (\n","        \"**Conclusion: The job is suspicious because it deviates significantly \"\n","        \"from typical, real job postings for similar roles.**\\n\\n\"\n","        \"**Analysis based on top 3 closest legitimate examples:**\\n\"\n","        \"The following real job postings were retrieved as highly similar to the suspicious posting:\\n\\n\"\n","        f\"{context_str}\\n\\n\"\n","        \"**Key Differences (LLM Explanation):**\\n\"\n","        \"While the retrieved examples feature detailed company profiles, specific contact details, \"\n","        \"and balanced language, the suspicious posting is likely missing one or more of these elements. \"\n","        \"This type of explanation confirms the suspicious nature by showing it is an 'outlier' \"\n","        \"compared to verified postings.\"\n","    )\n","\n","    return simulated_explanation"],"metadata":{"id":"toCVI2oBOo6T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Demonstration with a New Posting\n","We have demonstrate this powerful RAG system using a known fake job."],"metadata":{"id":"wtHehVGkPEBp"}},{"cell_type":"code","source":["#  RAG Demonstration (Using a Known Fake Job)\n","\n","# Get a known fake job posting\n","fake_post = df[df['fraudulent'] == 1].iloc[0]\n","\n","# Combine key text fields for the query to the vector store\n","job_text_query = combine_job_text(fake_post)\n","\n","print(f\"--- FAKE JOB POSTING (Actual Label: 1) ---\")\n","print(f\"Title: {fake_post['title']}\\nDescription Snippet: {fake_post['description'][:200]}...\")\n","print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Run Advanced RAG\n","explanation = retrieve_and_explain_similarity(job_text_query, real_job_kb)\n","\n","print(\"--- RAG-GENERATED EXPLANATION (Similarity-Based) ---\")\n","print(explanation)"],"metadata":{"id":"WyreqnhCO9la"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. pushing to github"],"metadata":{"id":"yAOA2B9fQW4k"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Fake_Job_Posting_Detection\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1A1BZ10JRjf7","executionInfo":{"status":"ok","timestamp":1765737762400,"user_tz":-300,"elapsed":253,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"dbea4daa-8192-4ede-f9b4-bb7af49a414f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Fake_Job_Posting_Detection\n"]}]},{"cell_type":"code","source":["!ls -a\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mTlpHFrQcS8","executionInfo":{"status":"ok","timestamp":1765737764242,"user_tz":-300,"elapsed":122,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"75702468-f73b-41ce-e967-1684264e6f34"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["data  .git  .gitignore\tmodels\tnotebooks  README.md  src\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaR7G_OvRLiS","executionInfo":{"status":"ok","timestamp":1765737773791,"user_tz":-300,"elapsed":7487,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"7554a6e6-3c8e-429f-ba83-d2891d276698"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Refresh index:  50% (3/6)\rRefresh index:  66% (4/6)\rRefresh index:  83% (5/6)\rRefresh index: 100% (6/6)\rRefresh index: 100% (6/6), done.\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   notebooks/03_Model_Training_Evaluation.ipynb\u001b[m\n","\t\u001b[31mmodified:   notebooks/04_RAG_Implementation.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mdata/\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!ls -R\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUZUSUosSBd-","executionInfo":{"status":"ok","timestamp":1765737777381,"user_tz":-300,"elapsed":124,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"609c1c1d-36ed-4f5a-d1fa-c72589b398ec"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[".:\n","data  models  notebooks  README.md  src\n","\n","./data:\n","processed_data.csv  raw\n","\n","./data/raw:\n","fake_job_postings.csv\n","\n","./models:\n","\n","./notebooks:\n","01_exploratry_data_analysis.ipynb  03_Model_Training_Evaluation.ipynb\n","02_preprocessing.ipynb\t\t   04_RAG_Implementation.ipynb\n","\n","./src:\n"]}]},{"cell_type":"code","source":["!git add notebooks/04_RAG_Implementation.ipynb"],"metadata":{"id":"MKUYpS12Srl1","executionInfo":{"status":"ok","timestamp":1765737788744,"user_tz":-300,"elapsed":507,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"muhammadriaz8685@gmail.com\"\n","!git config --global user.name \"mriaz72\""],"metadata":{"id":"Eh3nYpRdS8eb","executionInfo":{"status":"ok","timestamp":1765737791638,"user_tz":-300,"elapsed":216,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!git commit -m \" Implemented advanced RAG using real job postings as context for similarity-based explanations.\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_rQHtg0S_uM","executionInfo":{"status":"ok","timestamp":1765737795912,"user_tz":-300,"elapsed":2518,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"8c44948f-53b2-4c65-e9bd-187d6c1a3ee3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[main df16188]  Implemented advanced RAG using real job postings as context for similarity-based explanations.\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite notebooks/04_RAG_Implementation.ipynb (99%)\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1jE-cuxTI0a","executionInfo":{"status":"ok","timestamp":1765737801693,"user_tz":-300,"elapsed":4025,"user":{"displayName":"Muhammad Riaz","userId":"16061718774022103952"}},"outputId":"cd19b9f3-5918-4982-c188-41e9e8f362d0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 1\rEnumerating objects: 7, done.\n","Counting objects:  14% (1/7)\rCounting objects:  28% (2/7)\rCounting objects:  42% (3/7)\rCounting objects:  57% (4/7)\rCounting objects:  71% (5/7)\rCounting objects:  85% (6/7)\rCounting objects: 100% (7/7)\rCounting objects: 100% (7/7), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  25% (1/4)\rCompressing objects:  50% (2/4)\rCompressing objects:  75% (3/4)\rCompressing objects: 100% (4/4)\rCompressing objects: 100% (4/4), done.\n","Writing objects:  25% (1/4)\rWriting objects:  50% (2/4)\rWriting objects:  75% (3/4)\rWriting objects: 100% (4/4)\rWriting objects: 100% (4/4), 969 bytes | 484.00 KiB/s, done.\n","Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n","To https://github.com/mriaz72/Fake_Job_Posting_Detection.git\n","   0b2547a..df16188  main -> main\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cbhR5LdcTbGP"},"execution_count":null,"outputs":[]}]}