{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1bY6hxfktjLaCxMdnuWuEqOpQ8q2O6GRi","authorship_tag":"ABX9TyNce5PZgYty8ILSgKzwyXzU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Setup, Library Installation, and Data Preparation\n","We have load the necessary libraries and segment the dataset to create our knowledge base of real jobs."],"metadata":{"id":"2V6Ev-tJKwej"}},{"cell_type":"code","source":["!pip install -U langchain langchain-community sentence-transformers faiss-cpu -qq\n"],"metadata":{"id":"LttMmg45MID4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import pandas as pd\n","import numpy as np\n","import faiss\n","from sentence_transformers import SentenceTransformer\n","from langchain_community.embeddings import SentenceTransformerEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.documents import Document\n"],"metadata":{"id":"_HcX3ehvLA9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Load the raw dataset\n","df = pd.read_csv('/content/drive/MyDrive/Fake_Job_Posting_Detection/data/raw/fake_job_postings.csv')\n","df.fillna('', inplace=True)\n","df.head(3)"],"metadata":{"id":"wdJz8oIWLcnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Setup Embedding Model\n","model_name = 'all-MiniLM-L6-v2'\n","model = SentenceTransformer(model_name)\n","embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n","\n","print(f\"Sentence Transformer Model ({model_name}) loaded.\")"],"metadata":{"id":"lIObRGiBNpU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Create the Knowledge Base Source (Real Job Postings)\n","# Filter for verified Real Job Postings (fraudulent == 0)\n","real_jobs_df = df[df['fraudulent'] == 0].sample(n=300, random_state=42)\n","# Sampling 300 posts as requested for a focused knowledge base.\n","\n","print(f\"Knowledge Base Source created with {len(real_jobs_df)} verified real job postings.\")"],"metadata":{"id":"bftrPHE6N3JZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Build the Vector Store (FAISS)\n","We have embed the text of the real job postings and store them in FAISS for fast retrieval."],"metadata":{"id":"IhBBLIs9OQV6"}},{"cell_type":"code","source":["# Embed Real Postings and Build FAISS Vector Store\n","\n","# Function to combine relevant text fields for the knowledge base\n","def combine_job_text(row):\n","    return (f\"Title: {row['title']}. Company: {row['company_profile']}. \"\n","            f\"Description: {row['description']}. Requirements: {row['requirements']}\")\n","\n","# 1. Prepare Documents\n","real_job_documents = []\n","for index, row in real_jobs_df.iterrows():\n","    real_job_documents.append(\n","        Document(\n","            page_content=combine_job_text(row),\n","            metadata={\"job_id\": row['job_id'], \"title\": row['title']}\n","        )\n","    )\n","\n"],"metadata":{"id":"Nw61AK5xOI0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Create FAISS Vector Store\n","# This process embeds the text content of all 300 real jobs.\n","real_job_kb = FAISS.from_documents(real_job_documents, embedding_function)\n","print(f\"FAISS Vector Store built with embeddings from {len(real_job_documents)} real job postings.\")"],"metadata":{"id":"w3O4hP60Of6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Implement the Advanced Retrieval Function\n","This function retrieves the most similar real job postings and uses them to explain why a suspicious post differs from the norm."],"metadata":{"id":"poRi0TUkOv7_"}},{"cell_type":"code","source":["#  Retrieval and Generation Function (Similarity-Based Explanation)\n","\n","def retrieve_and_explain_similarity(suspicious_job_text, real_job_kb, top_k=3):\n","    \"\"\"Retrieves similar real jobs to contrast with the suspicious job.\"\"\"\n","\n","    # 1. Retrieval: Find top_k most similar (legitimate) job postings\n","    retrieved_docs = real_job_kb.similarity_search(suspicious_job_text, k=top_k)\n","\n","    # 2. Construct the Prompt (Simulated LLM)\n","    context_list = []\n","    for i, doc in enumerate(retrieved_docs):\n","        # Limit content length for cleaner output\n","        content_snippet = doc.page_content[:150].replace('\\n', ' ') + '...'\n","        context_list.append(f\"Example {i+1} (Title: {doc.metadata['title']}): {content_snippet}\")\n","\n","    context_str = \"\\n\".join(context_list)\n","\n","    # 3. Generation (Simulated for this project)\n","    # The actual LLM prompt would ask for a contrastive explanation:\n","\n","    simulated_explanation = (\n","        \"**Conclusion: The job is suspicious because it deviates significantly \"\n","        \"from typical, real job postings for similar roles.**\\n\\n\"\n","        \"**Analysis based on top 3 closest legitimate examples:**\\n\"\n","        \"The following real job postings were retrieved as highly similar to the suspicious posting:\\n\\n\"\n","        f\"{context_str}\\n\\n\"\n","        \"**Key Differences (LLM Explanation):**\\n\"\n","        \"While the retrieved examples feature detailed company profiles, specific contact details, \"\n","        \"and balanced language, the suspicious posting is likely missing one or more of these elements. \"\n","        \"This type of explanation confirms the suspicious nature by showing it is an 'outlier' \"\n","        \"compared to verified postings.\"\n","    )\n","\n","    return simulated_explanation"],"metadata":{"id":"toCVI2oBOo6T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Demonstration with a New Posting\n","We have demonstrate this powerful RAG system using a known fake job."],"metadata":{"id":"wtHehVGkPEBp"}},{"cell_type":"code","source":["#  RAG Demonstration (Using a Known Fake Job)\n","\n","# Get a known fake job posting\n","fake_post = df[df['fraudulent'] == 1].iloc[0]\n","\n","# Combine key text fields for the query to the vector store\n","job_text_query = combine_job_text(fake_post)\n","\n","print(f\"--- FAKE JOB POSTING (Actual Label: 1) ---\")\n","print(f\"Title: {fake_post['title']}\\nDescription Snippet: {fake_post['description'][:200]}...\")\n","print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Run Advanced RAG\n","explanation = retrieve_and_explain_similarity(job_text_query, real_job_kb)\n","\n","print(\"--- RAG-GENERATED EXPLANATION (Similarity-Based) ---\")\n","print(explanation)"],"metadata":{"id":"WyreqnhCO9la"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. pushing to github"],"metadata":{"id":"yAOA2B9fQW4k"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Fake_Job_Posting_Detection\n"],"metadata":{"id":"1A1BZ10JRjf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -a\n"],"metadata":{"id":"5mTlpHFrQcS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git status\n"],"metadata":{"id":"qaR7G_OvRLiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -R\n"],"metadata":{"id":"RUZUSUosSBd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add notebooks/04_RAG_Implementation.ipynb"],"metadata":{"id":"MKUYpS12Srl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"muhammadriaz8685@gmail.com\"\n","!git config --global user.name \"mriaz72\""],"metadata":{"id":"Eh3nYpRdS8eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \" Implemented advanced RAG using real job postings as context for similarity-based explanations.\""],"metadata":{"id":"R_rQHtg0S_uM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push"],"metadata":{"id":"X1jE-cuxTI0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push --force origin main"],"metadata":{"id":"Kju9g7F_TM18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cbhR5LdcTbGP"},"execution_count":null,"outputs":[]}]}